{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f975fabcf55d3507"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Project Title and Authors\n",
    "Project Title: NBA Predictor\n",
    "Authors: Sam Motto and Alex Lehman"
   ],
   "id": "95db9a0470488414"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\"Introduce the regression or classification task your group has chosen. Specify clearly whether it is a regression or a classification problem. Provide a reference or note the source of your dataset (e.g., UCI, Kaggle, Googleâ€™s Dataset Search, etc.).\"\n",
    "\n"
   ],
   "id": "31013f693d7efb26"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T20:59:17.709045300Z",
     "start_time": "2025-04-08T20:59:17.408749700Z"
    }
   },
   "id": "4970c645c0f2804"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Methods: Data\n",
    "\"Describe your dataset in detail. Include its source, key features, and any important contextual information. Explain the data cleaning or pre-processing steps and how you split the data into training/validation and test sets.\""
   ],
   "id": "2baf93fb5796406d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T21:08:37.457590100Z",
     "start_time": "2025-04-08T21:08:16.428249200Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2004 season...\n",
      "Skipping 2004 already have data.\n",
      "Processing 2005 season...\n",
      "Skipping 2005 already have data.\n",
      "Processing 2006 season...\n",
      "Skipping 2006 already have data.\n",
      "Processing 2007 season...\n",
      "Skipping 2007 already have data.\n",
      "Processing 2008 season...\n",
      "Skipping 2008 already have data.\n",
      "Processing 2009 season...\n",
      "Skipping 2009 already have data.\n",
      "Processing 2010 season...\n",
      "Skipping 2010 already have data.\n",
      "Processing 2011 season...\n",
      "Skipping 2011 already have data.\n",
      "Processing 2012 season...\n",
      "Skipping 2012 already have data.\n",
      "Processing 2013 season...\n",
      "Skipping 2013 already have data.\n",
      "Processing 2014 season...\n",
      "Skipping 2014 already have data.\n",
      "Processing 2015 season...\n",
      "Skipping 2015 already have data.\n",
      "Processing 2016 season...\n",
      "Skipping 2016 already have data.\n",
      "Processing 2017 season...\n",
      "Skipping 2017 already have data.\n",
      "Processing 2018 season...\n",
      "Skipping 2018 already have data.\n",
      "Processing 2019 season...\n",
      "Skipping 2019 already have data.\n",
      "Processing 2020 season...\n",
      "Skipping 2020 already have data.\n",
      "Processing 2021 season...\n",
      "Skipping 2021 already have data.\n",
      "Processing 2022 season...\n",
      "Skipping 2022 already have data.\n",
      "Processing 2023 season...\n",
      "Skipping 2023 already have data.\n",
      "Processing 2024 season...\n",
      "Skipping 2024 already have data.\n"
     ]
    }
   ],
   "execution_count": 6,
   "source": [
    "# --------------------------\n",
    "# Helper: Clean Team Name\n",
    "# --------------------------\n",
    "def clean_team_name(name):\n",
    "    return re.sub(r'[^\\w\\s]', '', name).strip()\n",
    "\n",
    "# --------------------------\n",
    "# Fetch and Process Tables\n",
    "# --------------------------\n",
    "def fetch_table(url, table_id):\n",
    "    header = 1 if table_id == 'advanced-team' else 0\n",
    "    df = pd.read_html(url, header=header, attrs={'id': table_id})[0]\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    for col in [\"Rk\", \"Arena\", \"Attend.\", \"Attend./G\"]:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "\n",
    "    if \"Team\" in df.columns:\n",
    "        df[\"Team\"] = df[\"Team\"].astype(str).apply(clean_team_name)\n",
    "\n",
    "    if table_id == 'advanced-team':\n",
    "        df = df[:-1].reset_index(drop=True)\n",
    "        rename_map = {\n",
    "            \"eFG%\": \"Off_eFG%\",\n",
    "            \"TOV%\": \"Off_TOV%\",\n",
    "            \"FT/FGA\": \"Off_FT/FGA\",\n",
    "            \"eFG%.1\": \"Def_eFG%\",\n",
    "            \"TOV%.1\": \"Def_TOV%\",\n",
    "            \"FT/FGA.1\": \"Def_FT/FGA\"\n",
    "        }\n",
    "        df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --------------------------\n",
    "# Download and Combine Data\n",
    "# --------------------------\n",
    "base_url = \"https://www.basketball-reference.com/leagues/NBA_{}.html\"\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for year in range(2004, 2025):\n",
    "    print(f\"Processing {year} season...\")\n",
    "    url = base_url.format(year)\n",
    "\n",
    "    df_advanced = None\n",
    "    df_perposs = None\n",
    "\n",
    "    try:\n",
    "        # NOTE: We have already provided the data from 2004-2024\n",
    "        # If you try to fetch too many tables at once you get blacklisted for being a bot\n",
    "        #df_advanced = fetch_table(url, \"advanced-team\")\n",
    "        #df_perposs = fetch_table(url, \"per_poss-team\")\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data for {year}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if df_advanced is not None and df_perposs is not None:\n",
    "        merged = pd.merge(df_advanced, df_perposs, on=\"Team\", suffixes=(\"_adv\", \"_poss\"))\n",
    "        merged[\"Year\"] = year\n",
    "        merged.to_csv(f\"data/{year}_merged.csv\", index=False)\n",
    "        print(f\"Saved merged data to data/{year}_merged.csv\")\n",
    "    else:\n",
    "        print(f\"Skipping {year} already have data.\")\n",
    "\n",
    "    time.sleep(1)"
   ],
   "id": "75083799bdd6a46f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Combine All and Add Champion Label\n",
    "# --------------------------\n",
    "print(\"\\nMerging all years into one file...\")\n",
    "\n",
    "# Load and concatenate all year files\n",
    "all_years = []\n",
    "for filename in os.listdir(\"data\"):\n",
    "    if filename.endswith(\"_merged.csv\"):\n",
    "        all_years.append(pd.read_csv(os.path.join(\"data\", filename)))\n",
    "df = pd.concat(all_years, ignore_index=True)\n",
    "\n",
    "# Champion team per year\n",
    "champion_teams = {\n",
    "    \"2004\": \"Detroit Pistons\",\n",
    "    \"2005\": \"San Antonio Spurs\",\n",
    "    \"2006\": \"Miami Heat\",\n",
    "    \"2007\": \"San Antonio Spurs\",\n",
    "    \"2008\": \"Boston Celtics\",\n",
    "    \"2009\": \"Los Angeles Lakers\",\n",
    "    \"2010\": \"Los Angeles Lakers\",\n",
    "    \"2011\": \"Dallas Mavericks\",\n",
    "    \"2012\": \"Miami Heat\",\n",
    "    \"2013\": \"Miami Heat\",\n",
    "    \"2014\": \"San Antonio Spurs\",\n",
    "    \"2015\": \"Golden State Warriors\",\n",
    "    \"2016\": \"Cleveland Cavaliers\",\n",
    "    \"2017\": \"Golden State Warriors\",\n",
    "    \"2018\": \"Golden State Warriors\",\n",
    "    \"2019\": \"Toronto Raptors\",\n",
    "    \"2020\": \"Los Angeles Lakers\",\n",
    "    \"2021\": \"Milwaukee Bucks\",\n",
    "    \"2022\": \"Golden State Warriors\",\n",
    "    \"2023\": \"Denver Nuggets\",\n",
    "}\n",
    "\n",
    "# Clean team names just in case\n",
    "df[\"Team\"] = df[\"Team\"].astype(str).apply(clean_team_name)\n",
    "\n",
    "# Label champions\n",
    "df[\"Champion\"] = df.apply(\n",
    "    lambda row: 1 if row[\"Team\"].strip() == champion_teams.get(str(row[\"Year\"]), None) else 0, axis=1)\n",
    "\n",
    "# Save final combined file\n",
    "df.to_csv(\"combined_data_with_champions.csv\", index=False)\n",
    "print(\"Saved combined_data_with_champions.csv.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "724978fb83da98b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Methods: Training/Validation\n",
    "Describe how you performed the training/validation process. Summarize the at least five different model variations that you tried (e.g., changes in features, different algorithms, or hyperparameters) and explain your method for model selection."
   ],
   "id": "f8b0035532123199"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# put training here"
   ],
   "id": "20f0b1f93822e290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results on Test Set\n",
    "Describe how you evaluated your final model using the test set. Include key performance metrics and relevant visualizations (e.g., ROC curves, confusion matrices, graphs, summary statistics, accuracy, etc.)."
   ],
   "id": "e2a4f1d4c988021"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# put results on test set here"
   ],
   "id": "234ccdb0bf5f9379"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Discussion / Conclusion\n",
    "Discuss the outcomes of your project. Summarize your key findings, interpret the results, and offer reflections on what worked well and what could be improved in future iterations of your work."
   ],
   "id": "f82bbb4bc7781618"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Disclosures\n",
    "Include a brief description of your use of ChatGPT or any other AI tools to help with your project, if applicable."
   ],
   "id": "700b9913b22d703a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "7f456341b2660b3e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
