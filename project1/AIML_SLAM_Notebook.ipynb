{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f975fabcf55d3507"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Project Title and Authors\n",
    "Project Title: NBA Predictor\n",
    "Authors: Sam Motto and Alex Lehman"
   ],
   "id": "95db9a0470488414"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\"Introduce the regression or classification task your group has chosen. Specify clearly whether it is a regression or a classification problem. Provide a reference or note the source of your dataset (e.g., UCI, Kaggle, Googleâ€™s Dataset Search, etc.).\"\n",
    "\n"
   ],
   "id": "31013f693d7efb26"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T21:20:31.866083Z",
     "start_time": "2025-04-08T21:20:31.861506Z"
    }
   },
   "id": "4970c645c0f2804",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Methods: Data\n",
    "\"Describe your dataset in detail. Include its source, key features, and any important contextual information. Explain the data cleaning or pre-processing steps and how you split the data into training/validation and test sets.\""
   ],
   "id": "2baf93fb5796406d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T21:20:33.582969Z",
     "start_time": "2025-04-08T21:20:33.567191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------\n",
    "# Helper: Clean Team Name\n",
    "# --------------------------\n",
    "def clean_team_name(name):\n",
    "    return re.sub(r'[^\\w\\s]', '', name).strip()\n",
    "\n",
    "# --------------------------\n",
    "# Fetch and Process Tables\n",
    "# --------------------------\n",
    "def fetch_table(url, table_id):\n",
    "    header = 1 if table_id == 'advanced-team' else 0\n",
    "    df = pd.read_html(url, header=header, attrs={'id': table_id})[0]\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    for col in [\"Rk\", \"Arena\", \"Attend.\", \"Attend./G\"]:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "\n",
    "    if \"Team\" in df.columns:\n",
    "        df[\"Team\"] = df[\"Team\"].astype(str).apply(clean_team_name)\n",
    "\n",
    "    if table_id == 'advanced-team':\n",
    "        df = df[:-1].reset_index(drop=True)\n",
    "        rename_map = {\n",
    "            \"eFG%\": \"Off_eFG%\",\n",
    "            \"TOV%\": \"Off_TOV%\",\n",
    "            \"FT/FGA\": \"Off_FT/FGA\",\n",
    "            \"eFG%.1\": \"Def_eFG%\",\n",
    "            \"TOV%.1\": \"Def_TOV%\",\n",
    "            \"FT/FGA.1\": \"Def_FT/FGA\"\n",
    "        }\n",
    "        df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --------------------------\n",
    "# Download and Combine Data\n",
    "# --------------------------\n",
    "base_url = \"https://www.basketball-reference.com/leagues/NBA_{}.html\"\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for year in range(1990, 1995):\n",
    "    print(f\"Processing {year} season...\")\n",
    "    url = base_url.format(year)\n",
    "\n",
    "    df_advanced = None\n",
    "    df_perposs = None\n",
    "\n",
    "    try:\n",
    "        # NOTE: We have already provided the data from 2004-2024\n",
    "        # If you try to fetch too many tables at once you get blacklisted for being a bot\n",
    "        df_advanced = fetch_table(url, \"advanced-team\")\n",
    "        df_perposs = fetch_table(url, \"per_poss-team\")\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data for {year}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if df_advanced is not None and df_perposs is not None:\n",
    "        merged = pd.merge(df_advanced, df_perposs, on=\"Team\", suffixes=(\"_adv\", \"_poss\"))\n",
    "        merged[\"Year\"] = year\n",
    "        merged.to_csv(f\"data/{year}_merged.csv\", index=False)\n",
    "        print(f\"Saved merged data to data/{year}_merged.csv\")\n",
    "    else:\n",
    "        print(f\"Skipping {year} already have data.\")\n",
    "\n",
    "    time.sleep(1)"
   ],
   "id": "75083799bdd6a46f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1990 season...\n",
      "Failed to fetch data for 1990: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "Processing 1991 season...\n",
      "Failed to fetch data for 1991: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "Processing 1992 season...\n",
      "Failed to fetch data for 1992: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "Processing 1993 season...\n",
      "Failed to fetch data for 1993: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "Processing 1994 season...\n",
      "Failed to fetch data for 1994: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging all years into one file...\n",
      "Saved combined_data_with_champions.csv.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Combine All and Add Champion Label\n",
    "# --------------------------\n",
    "print(\"\\nMerging all years into one file...\")\n",
    "\n",
    "# Load and concatenate all year files\n",
    "all_years = []\n",
    "for filename in os.listdir(\"data\"):\n",
    "    if filename.endswith(\"_merged.csv\"):\n",
    "        all_years.append(pd.read_csv(os.path.join(\"data\", filename)))\n",
    "df = pd.concat(all_years, ignore_index=True)\n",
    "\n",
    "# Champion team per year\n",
    "champion_teams = {\n",
    "    \"2004\": \"Detroit Pistons\",\n",
    "    \"2005\": \"San Antonio Spurs\",\n",
    "    \"2006\": \"Miami Heat\",\n",
    "    \"2007\": \"San Antonio Spurs\",\n",
    "    \"2008\": \"Boston Celtics\",\n",
    "    \"2009\": \"Los Angeles Lakers\",\n",
    "    \"2010\": \"Los Angeles Lakers\",\n",
    "    \"2011\": \"Dallas Mavericks\",\n",
    "    \"2012\": \"Miami Heat\",\n",
    "    \"2013\": \"Miami Heat\",\n",
    "    \"2014\": \"San Antonio Spurs\",\n",
    "    \"2015\": \"Golden State Warriors\",\n",
    "    \"2016\": \"Cleveland Cavaliers\",\n",
    "    \"2017\": \"Golden State Warriors\",\n",
    "    \"2018\": \"Golden State Warriors\",\n",
    "    \"2019\": \"Toronto Raptors\",\n",
    "    \"2020\": \"Los Angeles Lakers\",\n",
    "    \"2021\": \"Milwaukee Bucks\",\n",
    "    \"2022\": \"Golden State Warriors\",\n",
    "    \"2023\": \"Denver Nuggets\",\n",
    "}\n",
    "\n",
    "# Clean team names just in case\n",
    "df[\"Team\"] = df[\"Team\"].astype(str).apply(clean_team_name)\n",
    "\n",
    "# Label champions\n",
    "df[\"Champion\"] = df.apply(\n",
    "    lambda row: 1 if row[\"Team\"].strip() == champion_teams.get(str(row[\"Year\"]), None) else 0, axis=1)\n",
    "\n",
    "# Save final combined file\n",
    "df.to_csv(\"data/combined_data_with_champions.csv\", index=False)\n",
    "print(\"Saved combined_data_with_champions.csv.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T21:11:41.009146300Z",
     "start_time": "2025-04-08T21:11:40.941406500Z"
    }
   },
   "id": "724978fb83da98b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Methods: Training/Validation\n",
    "Describe how you performed the training/validation process. Summarize the at least five different model variations that you tried (e.g., changes in features, different algorithms, or hyperparameters) and explain your method for model selection."
   ],
   "id": "f8b0035532123199"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# put training here"
   ],
   "id": "20f0b1f93822e290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results on Test Set\n",
    "Describe how you evaluated your final model using the test set. Include key performance metrics and relevant visualizations (e.g., ROC curves, confusion matrices, graphs, summary statistics, accuracy, etc.)."
   ],
   "id": "e2a4f1d4c988021"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# put results on test set here"
   ],
   "id": "234ccdb0bf5f9379"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Discussion / Conclusion\n",
    "Discuss the outcomes of your project. Summarize your key findings, interpret the results, and offer reflections on what worked well and what could be improved in future iterations of your work."
   ],
   "id": "f82bbb4bc7781618"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Disclosures\n",
    "We used ChatGPT to help clean up our code comments, basically turning our shorthand comments into clearer, more detailed explanations. We also used it for general debugging and figuring out where stuff was breaking.\n"
   ],
   "id": "700b9913b22d703a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "7f456341b2660b3e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
